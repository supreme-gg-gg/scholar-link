{"id": "http://arxiv.org/abs/2002.10319v2", "guidislink": true, "link": "http://arxiv.org/abs/2002.10319v2", "updated": "2020-09-30T09:14:50Z", "updated_parsed": [2020, 9, 30, 9, 14, 50, 2, 274, 0], "published": "2020-02-24T15:47:10Z", "published_parsed": [2020, 2, 24, 15, 47, 10, 0, 55, 0], "title": "Self-Adaptive Training: beyond Empirical Risk Minimization", "title_detail": {"type": "text/plain", "language": null, "base": "", "value": "Self-Adaptive Training: beyond Empirical Risk Minimization"}, "summary": "We propose self-adaptive training---a new training algorithm that dynamically\ncorrects problematic training labels by model predictions without incurring\nextra computational cost---to improve generalization of deep learning for\npotentially corrupted training data. This problem is crucial towards robustly\nlearning from data that are corrupted by, e.g., label noises and\nout-of-distribution samples. The standard empirical risk minimization (ERM) for\nsuch data, however, may easily overfit noises and thus suffers from sub-optimal\nperformance. In this paper, we observe that model predictions can substantially\nbenefit the training process: self-adaptive training significantly improves\ngeneralization over ERM under various levels of noises, and mitigates the\noverfitting issue in both natural and adversarial training. We evaluate the\nerror-capacity curve of self-adaptive training: the test error is monotonously\ndecreasing w.r.t. model capacity. This is in sharp contrast to the\nrecently-discovered double-descent phenomenon in ERM which might be a result of\noverfitting of noises. Experiments on CIFAR and ImageNet datasets verify the\neffectiveness of our approach in two applications: classification with label\nnoise and selective classification. We release our code at\nhttps://github.com/LayneH/self-adaptive-training.", "summary_detail": {"type": "text/plain", "language": null, "base": "", "value": "We propose self-adaptive training---a new training algorithm that dynamically\ncorrects problematic training labels by model predictions without incurring\nextra computational cost---to improve generalization of deep learning for\npotentially corrupted training data. This problem is crucial towards robustly\nlearning from data that are corrupted by, e.g., label noises and\nout-of-distribution samples. The standard empirical risk minimization (ERM) for\nsuch data, however, may easily overfit noises and thus suffers from sub-optimal\nperformance. In this paper, we observe that model predictions can substantially\nbenefit the training process: self-adaptive training significantly improves\ngeneralization over ERM under various levels of noises, and mitigates the\noverfitting issue in both natural and adversarial training. We evaluate the\nerror-capacity curve of self-adaptive training: the test error is monotonously\ndecreasing w.r.t. model capacity. This is in sharp contrast to the\nrecently-discovered double-descent phenomenon in ERM which might be a result of\noverfitting of noises. Experiments on CIFAR and ImageNet datasets verify the\neffectiveness of our approach in two applications: classification with label\nnoise and selective classification. We release our code at\nhttps://github.com/LayneH/self-adaptive-training."}, "authors": [{"name": "Lang Huang"}, {"name": "Chao Zhang"}, {"name": "Hongyang Zhang"}], "author_detail": {"name": "Hongyang Zhang"}, "author": "Hongyang Zhang", "arxiv_comment": "To appear in NeurIPS 2020", "links": [{"href": "http://arxiv.org/abs/2002.10319v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2002.10319v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}]}